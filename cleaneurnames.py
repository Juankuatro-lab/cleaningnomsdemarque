#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Script de nettoyage des mots-clÃ©s de marque pour SEMRush/Ahrefs
Application Streamlit
"""

import streamlit as st
import pandas as pd
import re
import io
from difflib import SequenceMatcher
from typing import List, Set, Tuple
import base64

class BrandKeywordCleaner:
    def __init__(self, similarity_threshold: float = 0.8):
        """
        Initialise le nettoyeur de mots-clÃ©s de marque.
        
        Args:
            similarity_threshold: Seuil de similaritÃ© (0.0 Ã  1.0)
        """
        self.similarity_threshold = similarity_threshold
        self.stop_words = {'store', 'shop', 'official', 'france', 'fr', 'com', 'net', 'org', 'eu', 'boutique', 'site'}
        
    def extract_brand_names(self, domains: List[str]) -> Set[str]:
        """
        Extrait les noms de marque Ã  partir des domaines.
        
        Args:
            domains: Liste des domaines Ã  analyser
            
        Returns:
            Set des noms de marque extraits
        """
        brand_names = set()
        
        for domain in domains:
            # Nettoyage du domaine
            clean_domain = domain.lower().strip()
            clean_domain = re.sub(r'^https?://', '', clean_domain)
            clean_domain = re.sub(r'^www\.', '', clean_domain)
            clean_domain = clean_domain.split('.')[0]
            
            # SÃ©paration par tirets et underscores
            parts = re.split(r'[-_]', clean_domain)
            
            for part in parts:
                if len(part) > 2 and part not in self.stop_words:
                    brand_names.add(part)
                    
        return brand_names
    
    def calculate_similarity(self, str1: str, str2: str) -> float:
        """
        Calcule la similaritÃ© entre deux chaÃ®nes.
        
        Args:
            str1, str2: ChaÃ®nes Ã  comparer
            
        Returns:
            Score de similaritÃ© (0.0 Ã  1.0)
        """
        return SequenceMatcher(None, str1.lower(), str2.lower()).ratio()
    
    def is_brand_term(self, keyword: str, brand_names: Set[str]) -> bool:
        """
        VÃ©rifie si un mot-clÃ© contient un terme de marque.
        
        Args:
            keyword: Mot-clÃ© Ã  analyser
            brand_names: Set des noms de marque
            
        Returns:
            True si le mot-clÃ© contient un terme de marque
        """
        keyword_lower = keyword.lower()
        
        # Recherche exacte
        for brand in brand_names:
            if brand.lower() in keyword_lower:
                return True
        
        # Recherche avec similaritÃ©
        words = re.findall(r'\b\w+\b', keyword_lower)
        for word in words:
            for brand in brand_names:
                similarity = self.calculate_similarity(word, brand)
                if similarity >= self.similarity_threshold:
                    return True
                    
        return False
    
    def load_dataframe(self, uploaded_file) -> List[str]:
        """
        Charge un fichier uploadÃ© et extrait les mots-clÃ©s.
        
        Args:
            uploaded_file: Fichier uploadÃ© via Streamlit
            
        Returns:
            Liste des mots-clÃ©s
        """
        keywords = []
        
        try:
            # DÃ©tection de l'extension
            if uploaded_file.name.lower().endswith('.csv'):
                df = pd.read_csv(uploaded_file, encoding='utf-8')
            else:
                df = pd.read_excel(uploaded_file)
            
            # Recherche de la colonne keyword
            keyword_column = None
            for col in df.columns:
                if 'keyword' in col.lower():
                    keyword_column = col
                    break
            
            if keyword_column is None:
                st.error(f"âš ï¸ Colonne 'keyword' non trouvÃ©e dans {uploaded_file.name}")
                st.write(f"Colonnes disponibles: {list(df.columns)}")
                return keywords
            
            # Extraction des mots-clÃ©s
            keywords = df[keyword_column].dropna().astype(str).tolist()
            keywords = [kw.strip() for kw in keywords if kw.strip()]
            
            st.success(f"âœ… {len(keywords)} mots-clÃ©s chargÃ©s depuis {uploaded_file.name}")
            
        except Exception as e:
            st.error(f"âŒ Erreur lors du chargement de {uploaded_file.name}: {str(e)}")
            
        return keywords
    
    def process_files(self, uploaded_files, domains: List[str]) -> Tuple[List[str], dict]:
        """
        Traite les fichiers et dÃ©tecte les termes de marque.
        
        Args:
            uploaded_files: Liste des fichiers uploadÃ©s
            domains: Liste des domaines
            
        Returns:
            Tuple (liste des termes de marque, statistiques)
        """
        with st.spinner("ğŸ” Extraction des noms de marque depuis les domaines..."):
            brand_names = self.extract_brand_names(domains)
            st.write(f"**Noms de marque dÃ©tectÃ©s:** {', '.join(sorted(brand_names))}")
        
        with st.spinner("ğŸ“ Chargement des fichiers..."):
            all_keywords = []
            
            for uploaded_file in uploaded_files:
                keywords = self.load_dataframe(uploaded_file)
                all_keywords.extend(keywords)
        
        total_keywords = len(all_keywords)
        st.write(f"**ğŸ“Š Total:** {total_keywords:,} mots-clÃ©s Ã  analyser")
        
        with st.spinner("ğŸ” DÃ©tection des termes de marque..."):
            progress_bar = st.progress(0)
            brand_terms = []
            
            for i, keyword in enumerate(all_keywords):
                if self.is_brand_term(keyword, brand_names):
                    brand_terms.append(keyword)
                
                # Mise Ã  jour de la barre de progression
                if i % 100 == 0:
                    progress_bar.progress((i + 1) / len(all_keywords))
            
            progress_bar.progress(1.0)
        
        # Suppression des doublons tout en gardant l'ordre
        unique_terms = list(dict.fromkeys(brand_terms))
        
        stats = {
            'total_keywords': total_keywords,
            'brand_terms_found': len(brand_terms),
            'unique_brand_terms': len(unique_terms),
            'brand_percentage': (len(brand_terms) / total_keywords * 100) if total_keywords > 0 else 0,
            'brand_names': brand_names
        }
        
        return unique_terms, stats
    
    def generate_regex(self, terms: List[str]) -> str:
        """
        GÃ©nÃ¨re une regex Ã  partir des termes de marque.
        
        Args:
            terms: Liste des termes de marque
            
        Returns:
            Regex string
        """
        # Ã‰chappement des caractÃ¨res spÃ©ciaux
        escaped_terms = [re.escape(term) for term in terms]
        return f"\\b({'|'.join(escaped_terms)})\\b"
    
    def generate_comma_list(self, terms: List[str]) -> str:
        """
        GÃ©nÃ¨re une liste sÃ©parÃ©e par des virgules.
        
        Args:
            terms: Liste des termes de marque
            
        Returns:
            String avec termes sÃ©parÃ©s par des virgules
        """
        return ', '.join(terms)

def create_download_link(content: str, filename: str, text: str) -> str:
    """
    CrÃ©e un lien de tÃ©lÃ©chargement pour du contenu texte.
    
    Args:
        content: Contenu Ã  tÃ©lÃ©charger
        filename: Nom du fichier
        text: Texte du lien
        
    Returns:
        HTML du lien de tÃ©lÃ©chargement
    """
    b64 = base64.b64encode(content.encode()).decode()
    return f'<a href="data:text/plain;base64,{b64}" download="{filename}">{text}</a>'

def main():
    """Interface Streamlit principale."""
    
    # Configuration de la page
    st.set_page_config(
        page_title="Nettoyeur de mots-clÃ©s de marque",
        page_icon="ğŸ”",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    # En-tÃªte
    st.title("ğŸ” Nettoyeur de mots-clÃ©s de marque")
    st.markdown("**Extrait automatiquement les termes de marque de vos donnÃ©es SEMRush/Ahrefs**")
    
    # Sidebar pour la configuration
    with st.sidebar:
        st.header("âš™ï¸ Configuration")
        
        # Domaines
        domains_input = st.text_area(
            "Domaines Ã  analyser",
            placeholder="nike.com\nadidas.fr\npuma-store.com",
            help="Un domaine par ligne ou sÃ©parÃ©s par des virgules"
        )
        
        # Seuil de similaritÃ©
        similarity = st.slider(
            "Seuil de similaritÃ© (%)",
            min_value=50,
            max_value=100,
            value=80,
            help="Plus le seuil est bas, plus l'outil dÃ©tectera de variantes (mais aussi plus de faux positifs)"
        )
        
        st.markdown("---")
        st.markdown("### ğŸ“‹ Instructions")
        st.markdown("""
        1. **Saisissez vos domaines** (un par ligne)
        2. **Ajustez le seuil** si nÃ©cessaire
        3. **Uploadez vos fichiers** Excel/CSV
        4. **Cliquez sur Analyser**
        5. **Copiez les rÃ©sultats** gÃ©nÃ©rÃ©s
        """)
    
    # Zone principale
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("ğŸ“ Upload des fichiers")
        
        uploaded_files = st.file_uploader(
            "Choisissez vos fichiers SEMRush/Ahrefs",
            type=['xlsx', 'xls', 'csv'],
            accept_multiple_files=True,
            help="Formats acceptÃ©s: Excel (.xlsx, .xls) et CSV"
        )
        
        if uploaded_files:
            st.success(f"âœ… {len(uploaded_files)} fichier(s) uploadÃ©(s)")
            with st.expander("ğŸ“‹ Fichiers uploadÃ©s"):
                for file in uploaded_files:
                    st.write(f"â€¢ {file.name} ({file.size:,} bytes)")
    
    with col2:
        st.header("ğŸ¯ Lancement")
        
        # Validation des entrÃ©es
        domains_valid = bool(domains_input.strip())
        files_valid = bool(uploaded_files)
        
        if not domains_valid:
            st.warning("âš ï¸ Veuillez saisir au moins un domaine")
        if not files_valid:
            st.warning("âš ï¸ Veuillez uploader au moins un fichier")
        
        # Bouton d'analyse
        analyze_btn = st.button(
            "ğŸš€ Analyser les fichiers",
            disabled=not (domains_valid and files_valid),
            use_container_width=True
        )
    
    # Traitement
    if analyze_btn and domains_valid and files_valid:
        # PrÃ©paration des domaines
        domains = []
        for line in domains_input.replace(',', '\n').split('\n'):
            domain = line.strip()
            if domain:
                domains.append(domain)
        
        # Initialisation du cleaner
        cleaner = BrandKeywordCleaner(similarity_threshold=similarity / 100)
        
        try:
            # Traitement
            terms, stats = cleaner.process_files(uploaded_files, domains)
            
            if not terms:
                st.warning("âš ï¸ Aucun terme de marque dÃ©tectÃ©")
                return
            
            # Affichage des statistiques
            st.header("ğŸ“Š RÃ©sultats de l'analyse")
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("Mots-clÃ©s analysÃ©s", f"{stats['total_keywords']:,}")
            with col2:
                st.metric("Termes dÃ©tectÃ©s", f"{stats['brand_terms_found']:,}")
            with col3:
                st.metric("Termes uniques", f"{stats['unique_brand_terms']:,}")
            with col4:
                st.metric("% de marque", f"{stats['brand_percentage']:.1f}%")
            
            # GÃ©nÃ©ration des rÃ©sultats
            regex = cleaner.generate_regex(terms)
            comma_list = cleaner.generate_comma_list(terms)
            
            # Affichage des rÃ©sultats
            st.header("ğŸ¯ RÃ©sultats gÃ©nÃ©rÃ©s")
            
            # Regex
            st.subheader("ğŸ” Regex gÃ©nÃ©rÃ©e")
            st.code(regex, language="regex")
            if st.button("ğŸ“‹ Copier la regex", key="copy_regex"):
                st.success("Regex copiÃ©e ! (simulÃ©)")
            
            # Liste des termes
            st.subheader("ğŸ·ï¸ Liste des termes (sÃ©parÃ©s par virgules)")
            st.text_area(
                "Termes:",
                value=comma_list,
                height=100,
                key="comma_list"
            )
            if st.button("ğŸ“‹ Copier la liste", key="copy_list"):
                st.success("Liste copiÃ©e ! (simulÃ©)")
            
            # DÃ©tail des termes
            with st.expander("ğŸ“‹ DÃ©tail des termes dÃ©tectÃ©s", expanded=False):
                detail_list = '\n'.join([f"{i+1:4d}. {term}" for i, term in enumerate(terms)])
                st.text_area(
                    "Tous les termes:",
                    value=detail_list,
                    height=300,
                    key="detail_list"
                )
            
            # TÃ©lÃ©chargement des rÃ©sultats
            st.subheader("ğŸ’¾ TÃ©lÃ©chargement")
            
            # PrÃ©paration du contenu complet
            results_content = f"""RÃ‰SULTATS DE L'ANALYSE DES MOTS-CLÃ‰S DE MARQUE
{'=' * 80}

ğŸ“Š STATISTIQUES
{'-' * 40}
Mots-clÃ©s analysÃ©s: {stats['total_keywords']:,}
Termes de marque dÃ©tectÃ©s: {stats['brand_terms_found']:,}
Termes uniques: {stats['unique_brand_terms']:,}
Pourcentage de marque: {stats['brand_percentage']:.1f}%
Noms de marque utilisÃ©s: {', '.join(sorted(stats['brand_names']))}
Seuil de similaritÃ©: {similarity}%

ğŸ” REGEX GÃ‰NÃ‰RÃ‰E
{'-' * 40}
{regex}

ğŸ·ï¸ LISTE DES TERMES (sÃ©parÃ©s par virgules)
{'-' * 40}
{comma_list}

ğŸ“‹ DÃ‰TAIL DES TERMES DÃ‰TECTÃ‰S
{'-' * 40}
{detail_list}
"""
            
            st.download_button(
                label="â¬‡ï¸ TÃ©lÃ©charger les rÃ©sultats complets",
                data=results_content,
                file_name="brand_keywords_results.txt",
                mime="text/plain",
                use_container_width=True
            )
            
            st.success("âœ… Analyse terminÃ©e avec succÃ¨s !")
            
        except Exception as e:
            st.error(f"âŒ Erreur lors de l'analyse: {str(e)}")

if __name__ == "__main__":
    main()
